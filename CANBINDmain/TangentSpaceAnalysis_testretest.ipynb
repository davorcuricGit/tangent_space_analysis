{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d357a3-695c-4ef5-b69f-f997d47a6c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\davcu\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "C:\\Users\\davcu\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\davcu\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\davcu\\AppData\\Local\\Temp\\ipykernel_10808\\1022575765.py:9: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'TSAfuncs' from 'D:\\\\PhD/tangent_space_analysis\\\\TSAfuncs.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import h5py\n",
    "import scipy.io\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.linalg import logm,expm, sqrtm\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import mode\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"D:/PhD/tangent_space_analysis/\")\n",
    "                \n",
    "import TSAfuncs as tsa\n",
    "importlib.reload(tsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5af5efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = scipy.io.loadmat('filteredROI.mat')\n",
    "ROI = ROI['ROItokeep']\n",
    "nparcels = [100, 400, 1000]\n",
    "ROI_to_keep = dict()\n",
    "for i,n in enumerate(nparcels):\n",
    "    ROI_to_keep[n] = ROI[0][i][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2527498a-dadb-47b0-8c3f-3b945f1a5202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01CAM0005_recid=710.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01MCU0011_recid=729.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01MCU0055_recid=757.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01TGH0002_recid=794.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01TGH0077_recid=825.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01TGH0078_recid=826.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01TGH0080_recid=828.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01UBC0049_recid=859.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01UBC0067_recid=876.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01UCA0024_recid=893.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01CAM0005_recid=1244.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01MCU0011_recid=1260.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01TGH0002_recid=1316.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01TGH0077_recid=1347.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01TGH0078_recid=1348.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01TGH0080_recid=1350.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01UBC0049_recid=1382.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01UBC0067_recid=1398.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01UCA0024_recid=1413.mat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "parent_dir = os.getcwd()\n",
    "\n",
    "#parent_dir = 'parent dir here'\n",
    "dfOG = pd.read_csv(parent_dir + \"\\\\\" + 'allRecordings_dataframe.csv')\n",
    "\n",
    "dfOG = dfOG[dfOG['numparcels'] == 100]\n",
    "# dfOG = dfOG[(dfOG['Num Subnets'] == 17) & (dfOG['Num Parcels'] == 300)]\n",
    "# tasklist = ['Rest', 'Motor']#, 'Memory']\n",
    "FCs = list()\n",
    "\n",
    "# rest_df = pd.DataFrame()\n",
    "# dfOG.head(10)\n",
    "\n",
    "for index,row in dfOG.iterrows():\n",
    "    filename = row['filepath'] +'/' + 'FCs/' +'FC_' + row['subject'] + '_recid=' + str(row['recid']) + '.mat' #+ row['filename']\n",
    "    filename = filename.replace( '/scratch2/DavorCuric/CANBIND/' ,\"D:/PhD/CANBIND/\")\n",
    "    \n",
    "    try:\n",
    "        f = scipy.io.loadmat(filename)\n",
    "        subject_id = str(row['subject'])\n",
    "        state = int(row['controls'])*'controls' + int(row['nonresponders'])*'nonresponders' + int(row['responders'])*'responders'\n",
    "        \n",
    "        session = row['session']\n",
    "\n",
    "        if state == 'controls':\n",
    "            continue\n",
    "        if state == '':\n",
    "            continue\n",
    "\n",
    "        FCs.append(tsa.FC(np.array(f['FC']), subject = subject_id, state = state, session = session))\n",
    "    except:\n",
    "        print('file not found: ' + filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e848b756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tangent space score = 0.930894308943087, non-tangent space score = 0.861788617886177\n"
     ]
    }
   ],
   "source": [
    "#rest retest with identity reference\n",
    "\n",
    "regvals = np.array([1])#0.01, 0.1, 1, 10 ])\n",
    "trt = tsa.test_retest(FCs)\n",
    "\n",
    "for r in regvals:\n",
    "    score = trt.ts_test_retest(np.array([r]))#, refinv = 'logm')\n",
    "    score_classic = trt.classic_test_retest()\n",
    "    print('tangent space score = ' + str(score) + ', non-tangent space score = ' + str(score_classic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94cfdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"D:/PhD/tangent_space_analysis/\")\n",
    "                \n",
    "import TSAfuncs as tsa\n",
    "importlib.reload(tsa)\n",
    "\n",
    "#test retest with non-identity reference\n",
    "regvals = np.array([.01])#0.01, 0.1, 1, 10 ])\n",
    "trt = tsa.test_retest(FCs)\n",
    "\n",
    "\n",
    "#test with individual reg value\n",
    "for r in regvals:\n",
    "    score = trt.ts_test_retest(\n",
    "        regvals = np.array([r]), \n",
    "        refinv = 'logm'\n",
    "        )\n",
    "    \n",
    "    #subject_score_classic, state_score_classic, conditional_score_classic = trt.classic_test_retest()\n",
    "    #print('ts subject score = ' + str(subject_score) + ', non-ts subject score = ' + str(subject_score_classic))\n",
    "    #print('ts state score = ' + str(state_score) + ', non-ts state score = ' + str(state_score_classic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a4e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
