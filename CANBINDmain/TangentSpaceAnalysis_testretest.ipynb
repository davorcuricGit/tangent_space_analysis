{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d357a3-695c-4ef5-b69f-f997d47a6c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TSAfuncs' from 'D:\\\\PhD/tangent_space_analysis\\\\TSAfuncs.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import h5py\n",
    "import scipy.io\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.linalg import logm,expm, sqrtm\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import mode\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"D:/PhD/tangent_space_analysis/\")\n",
    "                \n",
    "import TSAfuncs as tsa\n",
    "importlib.reload(tsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5af5efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = scipy.io.loadmat('filteredROI.mat')\n",
    "ROI = ROI['ROItokeep']\n",
    "nparcels = [100, 400, 1000]\n",
    "ROI_to_keep = dict()\n",
    "for i,n in enumerate(nparcels):\n",
    "    ROI_to_keep[n] = ROI[0][i][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2527498a-dadb-47b0-8c3f-3b945f1a5202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01CAM0005_recid=710.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01MCU0011_recid=729.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01MCU0055_recid=757.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01TGH0002_recid=794.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01TGH0077_recid=825.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01TGH0078_recid=826.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01TGH0080_recid=828.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01UBC0049_recid=859.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01UBC0067_recid=876.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK2_100_PARCELS/FCs/FC_CBN01UCA0024_recid=893.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01CAM0005_recid=1244.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01MCU0011_recid=1260.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01TGH0002_recid=1316.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01TGH0077_recid=1347.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01TGH0078_recid=1348.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01TGH0080_recid=1350.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01UBC0049_recid=1382.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01UBC0067_recid=1398.mat\n",
      "file not found: D:/PhD/CANBIND/CANBIND_WK8_100_PARCELS/FCs/FC_CBN01UCA0024_recid=1413.mat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "parent_dir = os.getcwd()\n",
    "\n",
    "#parent_dir = 'parent dir here'\n",
    "dfOG = pd.read_csv(parent_dir + \"\\\\\" + 'allRecordings_dataframe.csv')\n",
    "\n",
    "dfOG = dfOG[dfOG['numparcels'] == 100]\n",
    "# dfOG = dfOG[(dfOG['Num Subnets'] == 17) & (dfOG['Num Parcels'] == 300)]\n",
    "# tasklist = ['Rest', 'Motor']#, 'Memory']\n",
    "FCs = list()\n",
    "\n",
    "# rest_df = pd.DataFrame()\n",
    "# dfOG.head(10)\n",
    "\n",
    "for index,row in dfOG.iterrows():\n",
    "    filename = row['filepath'] +'/' + 'FCs/' +'FC_' + row['subject'] + '_recid=' + str(row['recid']) + '.mat' #+ row['filename']\n",
    "    filename = filename.replace( '/scratch2/DavorCuric/CANBIND/' ,\"D:/PhD/CANBIND/\")\n",
    "    \n",
    "    try:\n",
    "        f = scipy.io.loadmat(filename)\n",
    "        subject_id = str(row['subject'])\n",
    "        state = int(row['controls'])*'controls' + int(row['nonresponders'])*'nonresponders' + int(row['responders'])*'responders'\n",
    "        \n",
    "        session = row['session']\n",
    "\n",
    "        if state == 'controls':\n",
    "            continue\n",
    "        if state == '':\n",
    "            continue\n",
    "\n",
    "        FCs.append(tsa.FC(np.array(f['FC']), subject = subject_id, state = state, session = session))\n",
    "    except:\n",
    "        print('file not found: ' + filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e848b756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1230, 1155)\n",
      "tangent space score = {'subject': 0.6951219512195117, 'state': 0.8414634146341446, 'condition': {0: 0.13023255813953494, 1: 0.14871794871794844}}, non-tangent space score = {'subject': 0.8455284552845511, 'state': 0.9146341463414611, 'condition': {0: 0.8139534883720942, 1: 0.8803418803418797}}\n"
     ]
    }
   ],
   "source": [
    "#rest retest with identity reference\n",
    "sys.path.insert(0, \"D:/PhD/tangent_space_analysis/\")\n",
    "                \n",
    "import TSAfuncs as tsa\n",
    "importlib.reload(tsa)\n",
    "\n",
    "regvals = np.array([5, 10, 100, 500, 1000])#0.01, 0.1, 1, 10 ])\n",
    "trt = tsa.test_retest(FCs)\n",
    "\n",
    "score = trt.ts_test_retest(regvals = regvals, use_pca = True, components = 75, mode = 'lowpass')#, refinv = 'logm')\n",
    "score_classic = trt.classic_test_retest()\n",
    "print('tangent space score = ' + str(score) + ', non-tangent space score = ' + str(score_classic))\n",
    "\n",
    "\n",
    "# for r in regvals:\n",
    "#     score = trt.ts_test_retest(regvals = np.array([r]), use_pca = True, components = 75, mode = 'lowpass')#, refinv = 'logm')\n",
    "#     score_classic = trt.classic_test_retest()\n",
    "#     print('tangent space score = ' + str(score) + ', non-tangent space score = ' + str(score_classic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94cfdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"D:/PhD/tangent_space_analysis/\")\n",
    "                \n",
    "import TSAfuncs as tsa\n",
    "importlib.reload(tsa)\n",
    "\n",
    "#test retest with non-identity reference\n",
    "regvals = np.array([.01])#0.01, 0.1, 1, 10 ])\n",
    "trt = tsa.test_retest(FCs)\n",
    "\n",
    "\n",
    "#test with individual reg value\n",
    "for r in regvals:\n",
    "    score = trt.ts_test_retest(\n",
    "        regvals = np.array([r]), \n",
    "        refinv = 'logm'\n",
    "        )\n",
    "    \n",
    "    #subject_score_classic, state_score_classic, conditional_score_classic = trt.classic_test_retest()\n",
    "    #print('ts subject score = ' + str(subject_score) + ', non-ts subject score = ' + str(subject_score_classic))\n",
    "    #print('ts state score = ' + str(state_score) + ', non-ts state score = ' + str(state_score_classic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a4e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
